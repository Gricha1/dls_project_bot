{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGANPROB",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Q2g2fEvcAu"
      },
      "source": [
        "#Загружаем требуемые библиотеки для загрузки данных и транформеры\r\n",
        "import os\r\n",
        "import torch\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torchvision\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from PIL import Image\r\n",
        "from torchvision.utils import save_image\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import warnings\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOapHcaxWDtW",
        "outputId": "29ca773e-ae7d-4d34-e87c-f60a1d384ff3"
      },
      "source": [
        "#Связываем нотбук с гугл диском\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ3-qQM8vpRK"
      },
      "source": [
        "#Суть функции - получить генераторы батчей изображений(сжатых до размеров image_size) с заранее подготовленной\r\n",
        "#папки с гугл диска\r\n",
        "def get_data_loader(image_type, image_dir='/content/drive/MyDrive/summer2winter_yosemite', \r\n",
        "                    image_size=128, batch_size=16, num_workers=0):\r\n",
        "    \r\n",
        "    \r\n",
        "    transform = transforms.Compose([transforms.Resize(image_size), \r\n",
        "                                    transforms.ToTensor()])\r\n",
        "    \r\n",
        "\r\n",
        "    #заранее созданная папка с изображениями имеет путь - image dir\r\n",
        "    image_path =  image_dir\r\n",
        "    train_path = os.path.join(image_path, image_type)\r\n",
        "    test_path = os.path.join(image_path, 'test_{}'.format(image_type))\r\n",
        "\r\n",
        "    \r\n",
        "    train_dataset = datasets.ImageFolder(train_path, transform)\r\n",
        "    test_dataset = datasets.ImageFolder(test_path, transform)\r\n",
        "\r\n",
        "    #получение самих генераторов \r\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\r\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\r\n",
        "\r\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drkWmmJJv2J7"
      },
      "source": [
        "dataloader_X, test_dataloader_X = get_data_loader(image_type='summer')\r\n",
        "dataloader_Y, test_dataloader_Y = get_data_loader(image_type='winter')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCI0sxI2wxuB"
      },
      "source": [
        "\r\n",
        "def imshow(img):\r\n",
        "    npimg = img.numpy()\r\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\r\n",
        "    \r\n",
        "\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU7JybDNvT7N"
      },
      "source": [
        "#Наши изображения являются тензорами с диапазоном значений (0, 1)\r\n",
        "#функция scale изменяет диапазон картинки на (-1, +1) потому что так лучше работает))  \r\n",
        "def scale(x, feature_range=(-1, 1)):\r\n",
        "    min, max = feature_range\r\n",
        "    x = x * (max - min) + min\r\n",
        "    return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzrEHHiWALXC"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "#функция conv - возвращает последовательность слоев нейросети - Conv2d и Batchnorm(если указан) \r\n",
        "def conv(in_channels, out_channels, kernel_size, stride=2, padding=1, batch_norm=True):\r\n",
        "    layers = []\r\n",
        "    conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, \r\n",
        "                           kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\r\n",
        "    \r\n",
        "    layers.append(conv_layer)\r\n",
        "\r\n",
        "    if batch_norm:\r\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\r\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhNacGjeAO6_"
      },
      "source": [
        "#определяем наш дискриминатор - бинарный классификатор на фейк-рил изображение\r\n",
        "class Discriminator(nn.Module):\r\n",
        "    def __init__(self, conv_dim=64):\r\n",
        "        super(Discriminator, self).__init__()\r\n",
        "\r\n",
        "        self.conv1 = conv(3,64,4,batch_norm=False)\r\n",
        "        self.conv2 = conv(64,128,4)\r\n",
        "        self.conv3 = conv(128,256,4)\r\n",
        "        self.conv4 = conv(256,512,4)\r\n",
        "        \r\n",
        "        self.conv5 = conv(512,1,4,1,batch_norm=False)\r\n",
        "        \r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = F.relu(self.conv1(x))\r\n",
        "        x = F.relu(self.conv2(x))\r\n",
        "        x = F.relu(self.conv3(x))\r\n",
        "        x = F.relu(self.conv4(x))\r\n",
        "        x = self.conv5(x)\r\n",
        "        \r\n",
        "        return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDK9S_rtvlhm"
      },
      "source": [
        "# Bottleneck будущего генератора(часть между енкодером и декодером) задается с помощью класса ResidualBlock \r\n",
        "class ResidualBlock(nn.Module):\r\n",
        "    #conv_dim - колличество входных карт активаций в residualblock \r\n",
        "    def __init__(self, conv_dim):\r\n",
        "        super(ResidualBlock, self).__init__()\r\n",
        "        self.conv1 = conv(conv_dim,conv_dim,3,1)\r\n",
        "        self.conv2 = conv(conv_dim,conv_dim,3,1)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        input_x = x\r\n",
        "        x = F.relu(self.conv1(x))\r\n",
        "        x = input_x + self.conv2(x)\r\n",
        "        return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkKu4kgo2dQ3"
      },
      "source": [
        "#Так же как с енкодером прописываем вспомогательную функцию deconv для определения\r\n",
        "#слоев сети в части декодера\r\n",
        "def deconv(in_channels, out_channels, kernel_size, stride=2, padding=1, batch_norm=True):\r\n",
        "    layers = []\r\n",
        "    layers.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False))\r\n",
        "    if batch_norm:\r\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\r\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zq32R-82ru4"
      },
      "source": [
        "#Определение самого генератора вид - енкодер, bottleneck, декодер\r\n",
        "class CycleGenerator(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, conv_dim=64, n_res_blocks=6):\r\n",
        "        super(CycleGenerator, self).__init__()\r\n",
        "\r\n",
        "        #Encoder\r\n",
        "        self.enc_conv1 = conv(3,conv_dim,4,2)\r\n",
        "        self.enc_conv2 = conv(conv_dim,conv_dim*2,4,2)\r\n",
        "        self.enc_conv3 = conv(conv_dim*2,conv_dim*4,4,2)\r\n",
        "        \r\n",
        "\r\n",
        "        #BottleNeck\r\n",
        "        l = [ResidualBlock(conv_dim*4) for i in range(n_res_blocks)]\r\n",
        "        self.resBlock = nn.Sequential(*l)\r\n",
        "\r\n",
        "        #Decoder\r\n",
        "        self.dec_conv1 = deconv(conv_dim*4,conv_dim*2,4,2)\r\n",
        "        self.dec_conv2 = deconv(conv_dim*2,conv_dim,4,2)\r\n",
        "        self.dec_conv3 = deconv(conv_dim,3,4,2)\r\n",
        "       \r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = F.relu(self.enc_conv1(x))\r\n",
        "        x = F.relu(self.enc_conv2(x))\r\n",
        "        x = F.relu(self.enc_conv3(x))\r\n",
        "        \r\n",
        "        x = self.resBlock(x)\r\n",
        "        \r\n",
        "        x = F.relu(self.dec_conv1(x))\r\n",
        "        x = F.relu(self.dec_conv2(x))\r\n",
        "        x = F.tanh(self.dec_conv3(x))\r\n",
        "        return x\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ienWVyH84C0o"
      },
      "source": [
        "#функция create_model - создает конечную модель состоящую из двух генераторов \r\n",
        "#Из множества картинок с летом во множество картинок с зимой и наоборот\r\n",
        "#А так же из двух соотвествующих им декодеров\r\n",
        "def create_model(g_conv_dim=64, d_conv_dim=64, n_res_blocks=6):\r\n",
        "    \r\n",
        "    \r\n",
        "    #Генераторы\r\n",
        "    G_XtoY = CycleGenerator(g_conv_dim,n_res_blocks)\r\n",
        "    G_YtoX = CycleGenerator(g_conv_dim,n_res_blocks)\r\n",
        "    #Дискриминаторы\r\n",
        "    D_X = Discriminator(d_conv_dim)\r\n",
        "    D_Y = Discriminator(d_conv_dim)\r\n",
        "    #Кидаем все что можем на GPU\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        device = torch.device(\"cuda:0\")\r\n",
        "        G_XtoY.to(device)\r\n",
        "        G_YtoX.to(device)\r\n",
        "        D_X.to(device)\r\n",
        "        D_Y.to(device)\r\n",
        "        print('Models moved to GPU.')\r\n",
        "    else:\r\n",
        "        print('Only CPU available.')\r\n",
        "\r\n",
        "    return G_XtoY, G_YtoX, D_X, D_Y"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb2Fdk7x4Ity",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b120f62e-7c90-47d4-90cd-dcba5a81d6db"
      },
      "source": [
        "G_XtoY, G_YtoX, D_X, D_Y = create_model()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Models moved to GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUca9r3n27IK"
      },
      "source": [
        "#Лосс функция потребуется для обучения дискриминатора - будет сравнивать его выход с реальным изображанием\r\n",
        "def real_mse_loss(D_out):\r\n",
        "    return torch.mean((D_out-1)**2)\r\n",
        "#Лосс функция, которая высчитывает лосс предсказания дискриминатора на фековых изображениях\r\n",
        "def fake_mse_loss(D_out):\r\n",
        "    return torch.mean(D_out**2)\r\n",
        "\r\n",
        "#Лосс функция предназаченая для оценки реконструкции\r\n",
        "def cycle_consistency_loss(real_im, reconstructed_im, lambda_weight):\r\n",
        "    return torch.mean(torch.abs(real_im-reconstructed_im)) * lambda_weight"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56rpLHso3DrD"
      },
      "source": [
        "#В данном блоке задаем оптимизатор для нашей модели(Адам) и определяем гиперпараметры\r\n",
        "import torch.optim as optim\r\n",
        "lr= 0.0002\r\n",
        "beta1= 0.5\r\n",
        "beta2= 0.999\r\n",
        "\r\n",
        "g_params = list(G_XtoY.parameters()) + list(G_YtoX.parameters()) \r\n",
        "\r\n",
        "g_optimizer = optim.Adam(g_params, lr, [beta1, beta2])\r\n",
        "d_x_optimizer = optim.Adam(D_X.parameters(), lr, [beta1, beta2])\r\n",
        "d_y_optimizer = optim.Adam(D_Y.parameters(), lr, [beta1, beta2])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w50oAfyh3XPi"
      },
      "source": [
        "#Функция обучения нашей модели \r\n",
        "def training_loop(dataloader_X, dataloader_Y, test_dataloader_X, test_dataloader_Y, \r\n",
        "                  n_epochs=1000):\r\n",
        "    \r\n",
        "\r\n",
        "    print_every = 10\r\n",
        "    losses = []\r\n",
        "\r\n",
        "    test_iter_X = iter(test_dataloader_X)\r\n",
        "    test_iter_Y = iter(test_dataloader_Y)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    iter_X = iter(dataloader_X)\r\n",
        "    iter_Y = iter(dataloader_Y)\r\n",
        "    batches_per_epoch = min(len(iter_X), len(iter_Y))\r\n",
        "\r\n",
        "    for epoch in range(1, n_epochs+1):\r\n",
        "\r\n",
        "        if epoch % batches_per_epoch == 0:\r\n",
        "            iter_X = iter(dataloader_X)\r\n",
        "            iter_Y = iter(dataloader_Y)\r\n",
        "\r\n",
        "        images_X, _ = iter_X.next()\r\n",
        "        images_X = scale(images_X) \r\n",
        "\r\n",
        "        images_Y, _ = iter_Y.next()\r\n",
        "        images_Y = scale(images_Y)\r\n",
        "        \r\n",
        "  \r\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "        images_X = images_X.to(device)\r\n",
        "        images_Y = images_Y.to(device)\r\n",
        "\r\n",
        "    #Тренеровка ДИСКРИМИНАТОРА (D_X, D_Y)\r\n",
        "        d_x_optimizer.zero_grad()\r\n",
        "        #1. Имея два типа лосса вначале мы высчитываем ошибку на реальном изображении лета\r\n",
        "        #далее мы генерируем изображение лета и высчитываем уже ошибку фейка\r\n",
        "        D_X_real_loss = real_mse_loss(D_X(images_X))\r\n",
        "        G_Y2X_fake_image = G_YtoX(images_Y) \r\n",
        "        D_X_fake_loss = fake_mse_loss(D_X(G_Y2X_fake_image))\r\n",
        "        \r\n",
        "        #суммарная ошибка и бэк проп у первого дискриминатора\r\n",
        "        d_x_loss = D_X_real_loss + D_X_fake_loss\r\n",
        "        d_x_loss.backward()\r\n",
        "        d_x_optimizer.step()\r\n",
        "        \r\n",
        "        #2. делаем аналогичные действия (пункт 1.) для второго генератора\r\n",
        "        D_Y_real_loss = real_mse_loss(D_Y(images_Y))\r\n",
        "        G_X2Y_fake_image = G_XtoY(images_X) \r\n",
        "        D_Y_fake_loss = fake_mse_loss(D_Y(G_X2Y_fake_image))\r\n",
        "        \r\n",
        "        d_y_loss = D_Y_real_loss + D_Y_fake_loss\r\n",
        "        \r\n",
        "        d_y_loss.backward()\r\n",
        "        d_y_optimizer.step()\r\n",
        "\r\n",
        "\r\n",
        "    #Тренеровка ГЕНЕРАТОРА(G_YtoX, G_XtoY)\r\n",
        "        g_optimizer.zero_grad()\r\n",
        "\r\n",
        "        #1. Вначале первым генератором генерируем изображение лета G_X_img \r\n",
        "        #далее наш дискриминатор на сгенерированном изображении позвоялет оценить насколько мы ошиблись\r\n",
        "        #по сгенерированному изображению G_X_img восстанавливаем изображение зимы вторым генератором\r\n",
        "        G_X_img = G_YtoX(images_Y)\r\n",
        "        G_X_real_loss = real_mse_loss(D_X(G_X_img))\r\n",
        "        G_Y_reconstructed = G_XtoY(G_X_img)\r\n",
        "        #Высчитываем последнюю ошибку на полученном изображении зимы \r\n",
        "        G_Y_consistency_loss = cycle_consistency_loss(images_Y,G_Y_reconstructed,10)\r\n",
        "\r\n",
        "\r\n",
        "        #2. Повторяем те же самые действия(что в пункте 1), но с первоначальной генерацией изображения зимы\r\n",
        "        G_Y_img = G_XtoY(images_X)\r\n",
        "        G_Y_real_loss = real_mse_loss(D_Y(G_Y_img))\r\n",
        "        G_X_reconstructed = G_YtoX(G_Y_img)\r\n",
        "        G_X_consistency_loss = cycle_consistency_loss(images_X,G_X_reconstructed,10)\r\n",
        "    \r\n",
        "        #Суммарная ошибка, бэкпроп и все дела\r\n",
        "        g_total_loss = G_X_real_loss + G_Y_real_loss + G_Y_consistency_loss + G_X_consistency_loss\r\n",
        "        g_total_loss.backward()\r\n",
        "        g_optimizer.step()\r\n",
        "        \r\n",
        "      \r\n",
        "      #Вывод ошибки при обучении\r\n",
        "        if epoch % print_every == 0:\r\n",
        "            losses.append((d_x_loss.item(), d_y_loss.item(), g_total_loss.item()))\r\n",
        "            print('Epoch [{:5d}/{:5d}] | d_X_loss: {:6.4f} | d_Y_loss: {:6.4f} | g_total_loss: {:6.4f}'.format(\r\n",
        "                    epoch, n_epochs, d_x_loss.item(), d_y_loss.item(), g_total_loss.item()))\r\n",
        "        \r\n",
        "    return losses"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QSOUvWH3d3q"
      },
      "source": [
        "#Запускаем обучение, достаточное колличество эпох - 3000\r\n",
        "n_epochs = 4000\r\n",
        "\r\n",
        "losses = training_loop(dataloader_X, dataloader_Y, test_dataloader_X, test_dataloader_Y, n_epochs=n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgSszcudMUpT"
      },
      "source": [
        "torch.save(G_XtoY, 'drive/MyDrive/1_sum_wint.pth')\r\n",
        "torch.save(G_YtoX, 'drive/MyDrive/1_wint_sum.pth')"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}